"""Streamlit –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è RAG —Å–∏—Å—Ç–µ–º—ã —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º –∫ FastAPI –±—ç–∫–µ–Ω–¥—É."""

import streamlit as st
import pandas as pd
import asyncio
from typing import List, Dict, Any
import io
import time
import json
import logging

# –ò–º–ø–æ—Ä—Ç API –∫–ª–∏–µ–Ω—Ç–∞
from app.client.api_client import api_client
from app.logics.postgres_storage import postgres_storage

logger = logging.getLogger(__name__)


def run_async_fn(fn, *args):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –≤ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ Streamlit."""
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        return loop.run_until_complete(fn(*args))
    finally:
        loop.close()


async def check_api_connection():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ API."""
    health = await api_client.health_check()
    return health.get("status") == "healthy"


async def upload_document_async(file, index_name: str, use_semantic_chunking: bool = False, 
                                semantic_threshold: float = 0.8) -> str:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ API."""
    try:
        # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
        file_data = file.read()
        filename = file.name
        
        # –í—ã–∑—ã–≤–∞–µ–º API
        result = await api_client.upload_document(
            file_data=file_data,
            filename=filename,
            index_name=index_name,
            use_semantic_chunking=use_semantic_chunking,
            semantic_threshold=semantic_threshold
        )
        
        if result.get("error"):
            return f"–û—à–∏–±–∫–∞: {result.get('message', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}"
        
        if result.get("success"):
            message = result.get("message", "–î–æ–∫—É–º–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω")
            # chunks_count –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –Ω–∞ –≤–µ—Ä—Ö–Ω–µ–º —É—Ä–æ–≤–Ω–µ –æ—Ç–≤–µ—Ç–∞, –∞ –Ω–µ –≤ data
            chunks_count = result.get("chunks_count", 0)
            return f"{message}. –°–æ–∑–¥–∞–Ω–æ {chunks_count} —á–∞–Ω–∫–æ–≤."
        else:
            return f"–û—à–∏–±–∫–∞: {result.get('message', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}"
            
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ: {str(e)}"


async def get_indices_async() -> List[str]:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤ —á–µ—Ä–µ–∑ API."""
    try:
        indices = await api_client.get_indices()
        return indices
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤: {e}")
        return []


async def search_and_answer_async(
    query_text: str,
    index_name: str,
    semantic_weight: float,
    keyword_weight: float,
    size: int,
    use_hyde: bool = False,
    hyde_num_hypotheses: int = 1,
    reranking: bool = False
) -> Dict[str, Any]:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ API."""
    
    user_query = {
        "query_text": query_text,
        "index_name": index_name,
        "sematic": semantic_weight,
        "keyword": keyword_weight,
        "size": size,
        "use_hyde": use_hyde,
        "hyde_num_hypotheses": hyde_num_hypotheses,
        "reranking": reranking,
        "k": size,  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        "fields": ["text"],  # –ü–æ–ª—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        "trashold": 0.0,  # –ü–æ—Ä–æ–≥–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        "trashold_bertscore": 0.0,
        "query_embed": None  # –ë—É–¥–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –Ω–∞ –±—ç–∫–µ–Ω–¥–µ
    }
    
    # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —á–µ—Ä–µ–∑ API
    result = await api_client.generate_answer(user_query)
    return result


async def evaluate_rag_async(
    test_data: List[Dict[str, str]], 
    index_name: str,
    search_params: Dict[str, Any]
) -> Dict[str, Any]:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ RAG —á–µ—Ä–µ–∑ API."""
    
    # –°–æ–∑–¥–∞–µ–º CSV —Ñ–∞–π–ª –∏–∑ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    df = pd.DataFrame(test_data)
    csv_buffer = io.StringIO()
    df.to_csv(csv_buffer, index=False)
    csv_data = csv_buffer.getvalue().encode('utf-8')
    
    # –í—ã–∑—ã–≤–∞–µ–º API
    result = await api_client.evaluate_rag_batch(
        file_data=csv_data,
        filename="test_data.csv",
        index_name=index_name,
        search_params=search_params
    )
    
    if result.get("error"):
        raise Exception(f"–û—à–∏–±–∫–∞ API: {result.get('message')}")
    
    return result.get("data", {})


def create_streamlit_interface():
    """–°–æ–∑–¥–∞–µ—Ç –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å Streamlit."""
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    st.set_page_config(
        page_title="RAG PDF –°–∏—Å—Ç–µ–º–∞",
        page_icon="üìö",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    st.title("üìö RAG PDF –°–∏—Å—Ç–µ–º–∞")
    st.markdown("---")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ API
    if "api_status" not in st.session_state:
        with st.spinner("–ü—Ä–æ–≤–µ—Ä—è—é –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ API..."):
            api_connected = run_async_fn(check_api_connection)
            st.session_state.api_status = api_connected
    
    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ API
    if st.session_state.api_status:
        st.success("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ API —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
    else:
        st.error("‚ùå –ù–µ —É–¥–∞–µ—Ç—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ API. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –±—ç–∫–µ–Ω–¥ –∑–∞–ø—É—â–µ–Ω –Ω–∞ localhost:8000")
        st.info("–ó–∞–ø—É—Å—Ç–∏—Ç–µ –±—ç–∫–µ–Ω–¥ –∫–æ–º–∞–Ω–¥–æ–π: `uvicorn main:app --reload`")
        if st.button("–ü–æ–≤—Ç–æ—Ä–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É"):
            st.session_state.api_status = run_async_fn(check_api_connection)
            st.experimental_rerun()
        return
    
    # –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å —Å —Ä–µ–∂–∏–º–∞–º–∏
    with st.sidebar:
        st.header("üéõÔ∏è –ü–∞–Ω–µ–ª—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è")
        
        mode = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º:",
            [
                "–ü–æ–∏—Å–∫ –∏ –æ—Ç–≤–µ—Ç—ã",
                "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤", 
                "–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞",
                "–†–∞–∑–º–µ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–æ–≤",
                "–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"
            ]
        )
        
        if mode == "–ü–æ–∏—Å–∫ –∏ –æ—Ç–≤–µ—Ç—ã":
            st.subheader("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞")
            
            # –í—ã–±–æ—Ä –∏–Ω–¥–µ–∫—Å–∞
            with st.spinner("–ü–æ–ª—É—á–∞—é —Å–ø–∏—Å–æ–∫ –∏–Ω–¥–µ–∫—Å–æ–≤..."):
                indices = run_async_fn(get_indices_async)
            
            if indices:
                selected_index = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –∏–Ω–¥–µ–∫—Å:", indices)
            else:
                st.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞")
                selected_index = None
            
            # –í–µ—Å–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
            st.write("**–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤–µ—Å–æ–≤ –ø–æ–∏—Å–∫–∞:**")
            semantic_weight = st.slider("–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫", 0.0, 1.0, 0.7, 0.1)
            keyword_weight = st.slider("–ö–ª—é—á–µ–≤–æ–π –ø–æ–∏—Å–∫", 0.0, 1.0, 0.3, 0.1)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
            total = semantic_weight + keyword_weight
            if total > 0:
                semantic_weight = semantic_weight / total
                keyword_weight = keyword_weight / total
            else:
                semantic_weight, keyword_weight = 0.7, 0.3
            
            st.write(f"–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π: {semantic_weight:.2f}, –ö–ª—é—á–µ–≤–æ–π: {keyword_weight:.2f}")
            
            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            size = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤", 1, 20, 5)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
            st.subheader("–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏")
            
            use_hyde = st.checkbox(
                "HyDE (Hypothetical Document Embeddings)",
                help="–£–ª—É—á—à–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É—è –≥–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã"
            )
            
            hyde_num_hypotheses = 1
            if use_hyde:
                hyde_num_hypotheses = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–∏–ø–æ—Ç–µ–∑ HyDE", 1, 5, 1)
            
            reranking = st.checkbox(
                "ColBERT Reranking",
                help="–ü–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ —Å –ø–æ–º–æ—â—å—é ColBERT –º–æ–¥–µ–ª–∏"
            )
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            st.subheader("–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
            show_sources = st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏", value=True)
            show_context = st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç", value=False)
    
    # –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
    if mode == "–ü–æ–∏—Å–∫ –∏ –æ—Ç–≤–µ—Ç—ã":
        st.header("–ü–æ–∏—Å–∫ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤")
        
        # –ü–æ–ª–µ –≤–≤–æ–¥–∞ –∑–∞–ø—Ä–æ—Å–∞
        user_query = st.text_area(
            "–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å:",
            placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: –ß—Ç–æ —Ç–∞–∫–æ–µ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ?",
            height=100
        )
        
        col1, col2 = st.columns([1, 4])
        with col1:
            search_button = st.button("–ù–∞–π—Ç–∏ –æ—Ç–≤–µ—Ç", type="primary")
        with col2:
            if not selected_index:
                st.warning("–í—ã–±–µ—Ä–∏—Ç–µ –∏–Ω–¥–µ–∫—Å –¥–ª—è –ø–æ–∏—Å–∫–∞")
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞
        if search_button and user_query.strip() and selected_index:
            with st.spinner("–ò—â—É –æ—Ç–≤–µ—Ç..."):
                start_time = time.time()
                
                try:
                    # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –æ—Ç–≤–µ—Ç–∞
                    result = run_async_fn(
                        search_and_answer_async,
                        user_query,
                        selected_index,
                        semantic_weight,
                        keyword_weight,
                        size,
                        use_hyde,
                        hyde_num_hypotheses,
                        reranking
                    )
                    
                    if result.get("error"):
                        st.error(f"–û—à–∏–±–∫–∞ API: {result.get('message')}")
                        return
                    
                    search_time = time.time() - start_time
                    
                    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–∏—Å–∫–µ
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("–í—Ä–µ–º—è –ø–æ–∏—Å–∫–∞", f"{search_time:.2f} —Å–µ–∫")
                    with col2:
                        sources_count = len(result.get("sources", []))
                        st.metric("–ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –Ω–∞–π–¥–µ–Ω–æ", sources_count)
                    with col3:
                        images_count = len(result.get("images", []))
                        st.metric("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", images_count)
                    
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                    with st.expander("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–∏—Å–∫–µ", expanded=False):
                        search_info = result.get("search_info", {})
                        tech_info = search_info.get("technologies", {})
                        translation_info = search_info.get("translation", {})
                        
                        if translation_info:
                            if translation_info.get("translated"):
                                translated_query = translation_info.get("translated_query", "")
                                if translated_query:
                                    st.info("**–ü–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å:**")
                                    if isinstance(translated_query, list):
                                        for i, tq in enumerate(translated_query, 1):
                                            st.code(f"{i}. {tq}")
                                    else:
                                        st.code(translated_query)
                                else:
                                    query_lang = translation_info.get("query_language", "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
                                    doc_lang = translation_info.get("document_language", "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
                                    if query_lang != "unknown" and doc_lang != "unknown":
                                        st.success(f"**–Ø–∑—ã–∫–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç**: {query_lang} –∏ {doc_lang}")
                                
                                # –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ RAG
                                tech_status = []
                                if tech_info.get("hyde"):
                                    tech_status.append("HyDE: –ê–∫—Ç–∏–≤–µ–Ω")
                                if tech_info.get("reranking"):
                                    tech_status.append("ColBERT Reranking: –ê–∫—Ç–∏–≤–µ–Ω")
                                
                                if tech_status:
                                    for status in tech_status:
                                        st.success(status)
                                else:
                                    st.info("–ë–∞–∑–æ–≤—ã–π –ø–æ–∏—Å–∫")
                        
                        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –æ—Ç–≤–µ—Ç
                        st.subheader("–û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞")
                        answer = result.get("answer", "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç")
                        st.markdown(answer)
                        
                        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
                        if show_sources:
                            sources = result.get("sources", [])
                            if sources:
                                st.subheader("–ò—Å—Ç–æ—á–Ω–∏–∫–∏")
                                sources_df = pd.DataFrame(sources)
                                st.dataframe(sources_df, use_container_width=True)
                        
                        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
                        if show_context:
                            context = result.get("context_used", "")
                            if context:
                                st.subheader("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç")
                                with st.expander("–ü–æ–∫–∞–∑–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç"):
                                    st.text(context)
                        
                        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                        images = result.get("images", [])
                        if images:
                            st.subheader("–ù–∞–π–¥–µ–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
                            for i, img in enumerate(images, 1):
                                st.image(img.get("base64_data", ""), caption=f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {i}")
                
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {e}")
    
    elif mode == "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤":
        st.header("–ó–∞–≥—Ä—É–∑–∫–∞ PDF –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞")
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
            uploaded_file = st.file_uploader(
                "–í—ã–±–µ—Ä–∏—Ç–µ PDF —Ñ–∞–π–ª",
                type=['pdf'],
                help="–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ PDF —Ñ–∞–π–ª—ã"
            )
            
            # –ù–∞–∑–≤–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
            index_name = st.text_input(
                "–ù–∞–∑–≤–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞",
                placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: medical_docs, legal_docs",
                help="–í–≤–µ–¥–∏—Ç–µ —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞"
            )
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞ —á–∞–Ω–∫–∏
            st.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞ —á–∞–Ω–∫–∏")
            
            chunking_method = st.radio(
                "–ú–µ—Ç–æ–¥ —Ä–∞–∑–±–∏–µ–Ω–∏—è:",
                options=["–û–±—ã—á–Ω–æ–µ (–ø–æ –∞–±–∑–∞—Ü–∞–º)", "–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ"],
                help="–û–±—ã—á–Ω–æ–µ - –±—ã—Å—Ç—Ä–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ –∞–±–∑–∞—Ü–∞–º. –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ - —É–º–Ω–æ–µ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ —Å–º—ã—Å–ª—É."
            )
            
            use_semantic_chunking = chunking_method == "–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ"
            
            semantic_threshold = 0.8
            if use_semantic_chunking:
                semantic_threshold = st.slider(
                    "–ü–æ—Ä–æ–≥ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞",
                    min_value=0.1,
                    max_value=1.0,
                    value=0.8,
                    step=0.1,
                    help="–ß–µ–º –≤—ã—à–µ –∑–Ω–∞—á–µ–Ω–∏–µ, —Ç–µ–º –±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≥—Ä—É–ø–ø–∏—Ä—É—é—Ç—Å—è –≤ –æ–¥–∏–Ω —á–∞–Ω–∫"
                )
            
            # –ö–Ω–æ–ø–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏
            if st.button("–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç", type="primary"):
                if not uploaded_file:
                    st.error("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏")
                elif not index_name:
                    st.error("–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞")
                else:
                    with st.spinner("–ó–∞–≥—Ä—É–∂–∞—é –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä—É—é –¥–æ–∫—É–º–µ–Ω—Ç..."):
                        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
                        result = run_async_fn(
                            upload_document_async, 
                            uploaded_file, 
                            index_name,
                            use_semantic_chunking,
                            semantic_threshold
                        )
                        
                        if "—É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω" in result:
                            st.success(result)
                        else:
                            st.error(result)
        
        with col2:
            st.subheader("–î–æ—Å—Ç—É–ø–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã")
            with st.spinner("–ü–æ–ª—É—á–∞—é —Å–ø–∏—Å–æ–∫ –∏–Ω–¥–µ–∫—Å–æ–≤..."):
                indices = run_async_fn(get_indices_async)
            
            if indices:
                for idx in indices:
                    st.text(f"üìÅ {idx}")
            else:
                st.info("–ò–Ω–¥–µ–∫—Å—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    elif mode == "–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞":
        st.header("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ RAG")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞")
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ CSV —Ñ–∞–π–ª–∞
            test_file = st.file_uploader(
                "–í—ã–±–µ—Ä–∏—Ç–µ CSV —Ñ–∞–π–ª —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏",
                type=['csv'],
                help="CSV —Ñ–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫–∏ 'question' –∏ 'expected_answer'"
            )
            
            if test_file:
                try:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –ø–µ—Ä–µ–¥ —á—Ç–µ–Ω–∏–µ–º
                    file_size = test_file.size if hasattr(test_file, 'size') else 0
                    if file_size == 0:
                        st.error("–§–∞–π–ª –ø—É—Å—Ç. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞.")
                    else:
                        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∫—É—Ä—Å–æ—Ä –≤ –Ω–∞—á–∞–ª–æ —Ñ–∞–π–ª–∞
                        test_file.seek(0)
                        df = pd.read_csv(test_file, encoding='utf-8')
                        
                        st.write("**–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö:**")
                        st.dataframe(df.head(), use_container_width=True)
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω—É–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
                        columns = df.columns.tolist()
                        question_cols = [col for col in columns if 'question' in col.lower() or '–≤–æ–ø—Ä–æ—Å' in col.lower()]
                        answer_cols = [col for col in columns if 'answer' in col.lower() or '–æ—Ç–≤–µ—Ç' in col.lower()]
                        
                        if not question_cols or not answer_cols:
                            st.error("–í CSV —Ñ–∞–π–ª–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∫–æ–ª–æ–Ω–∫–∏ —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ (question/–≤–æ–ø—Ä–æ—Å) –∏ –æ—Ç–≤–µ—Ç–∞–º–∏ (answer/–æ—Ç–≤–µ—Ç)")
                        else:
                            st.success(f"–ù–∞–π–¥–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
                            st.info(f"–ö–æ–ª–æ–Ω–∫–∞ –≤–æ–ø—Ä–æ—Å–æ–≤: {question_cols[0]}")
                            st.info(f"–ö–æ–ª–æ–Ω–∫–∞ –æ—Ç–≤–µ—Ç–æ–≤: {answer_cols[0]}")
                
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        
        with col2:
            st.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
            
            # –í—ã–±–æ—Ä –∏–Ω–¥–µ–∫—Å–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            with st.spinner("–ü–æ–ª—É—á–∞—é —Å–ø–∏—Å–æ–∫ –∏–Ω–¥–µ–∫—Å–æ–≤..."):
                test_indices = run_async_fn(get_indices_async)
            
            if test_indices:
                test_index = st.selectbox("–ò–Ω–¥–µ–∫—Å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:", test_indices)
            else:
                st.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞")
                test_index = None
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–∏—Å–∫–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            st.write("**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞:**")
            test_semantic = st.slider("–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –≤–µ—Å", 0.0, 1.0, 0.7, 0.1, key="test_semantic")
            test_keyword = st.slider("–ö–ª—é—á–µ–≤–æ–π –≤–µ—Å", 0.0, 1.0, 0.3, 0.1, key="test_keyword")
            test_size = st.slider("–†–∞–∑–º–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤", 1, 20, 5, key="test_size")
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            test_hyde = st.checkbox("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å HyDE", key="test_hyde")
            test_reranking = st.checkbox("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ColBERT", key="test_reranking")
            
            # –ö–Ω–æ–ø–∫–∞ –∑–∞–ø—É—Å–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            if st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ", type="primary", disabled=not (test_file and test_index)):
                # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
                total = test_semantic + test_keyword
                if total > 0:
                    test_semantic = test_semantic / total
                    test_keyword = test_keyword / total
                else:
                    test_semantic, test_keyword = 0.7, 0.3
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
                try:
                    # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∫—É—Ä—Å–æ—Ä –≤ –Ω–∞—á–∞–ª–æ —Ñ–∞–π–ª–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω—ã–º —á—Ç–µ–Ω–∏–µ–º
                    test_file.seek(0)
                    df = pd.read_csv(test_file, encoding='utf-8')
                    
                    columns = df.columns.tolist()
                    question_cols = [col for col in columns if 'question' in col.lower() or '–≤–æ–ø—Ä–æ—Å' in col.lower()]
                    answer_cols = [col for col in columns if 'answer' in col.lower() or '–æ—Ç–≤–µ—Ç' in col.lower()]
                    
                    if not question_cols or not answer_cols:
                        st.error("–í CSV —Ñ–∞–π–ª–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∫–æ–ª–æ–Ω–∫–∏ —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ –∏ –æ—Ç–≤–µ—Ç–∞–º–∏")
                    else:
                        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
                        test_data = []
                        for index, row in df.iterrows():
                            question = str(row[question_cols[0]]).strip()
                            expected_answer = str(row[answer_cols[0]]).strip()
                            
                            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ø—É—Å—Ç—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
                            if question and question != 'nan' and expected_answer and expected_answer != 'nan':
                                test_data.append({
                                    'question': question,
                                    'expected_answer': expected_answer
                                })
                        
                        if not test_data:
                            st.error("–í —Ñ–∞–π–ª–µ –Ω–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –ø–∞—Ä –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ —è—á–µ–π–∫–∏ –∑–∞–ø–æ–ª–Ω–µ–Ω—ã.")
                        else:
                            st.info(f"–ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(test_data)} —Ç–µ—Å—Ç–æ–≤—ã—Ö –ø–∞—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                            
                            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞
                            search_params = {
                                'semantic_weight': test_semantic,
                                'keyword_weight': test_keyword,
                                'size': test_size,
                                'use_hyde': test_hyde,
                                'reranking': test_reranking,
                                'k': test_size
                            }
                            
                            # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
                            with st.spinner(f"–¢–µ—Å—Ç–∏—Ä—É—é {len(test_data)} –≤–æ–ø—Ä–æ—Å–æ–≤..."):
                                eval_result = run_async_fn(
                                    evaluate_rag_async,
                                    test_data,
                                    test_index,
                                    search_params
                                )
                            
                            # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                            st.success("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
                            
                            # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                            st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
                            
                            col1, col2, col3, col4 = st.columns(4)
                            
                            with col1:
                                total_tests = eval_result.get("total_tests", 0)
                                st.metric("–í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤", total_tests)
                                
                            with col2:
                                correct_answers = eval_result.get("correct_answers", 0)
                                st.metric("–ü—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤", correct_answers)
                                
                            with col3:
                                accuracy = eval_result.get("accuracy", 0)
                                st.metric("–¢–æ—á–Ω–æ—Å—Ç—å", f"{accuracy:.1%}")
                                
                            with col4:
                                avg_time = eval_result.get("average_time", 0)
                                st.metric("–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è", f"{avg_time:.2f} —Å–µ–∫")
                            
                            # –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                            st.subheader("–î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
                            
                            test_results = eval_result.get("test_results", [])
                            if test_results:
                                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                                results_data = []
                                for test in test_results:
                                    results_data.append({
                                        'ID': test.get('test_id', ''),
                                        '–í–æ–ø—Ä–æ—Å': test.get('question', '')[:50] + '...' if len(test.get('question', '')) > 50 else test.get('question', ''),
                                        '–û–∂–∏–¥–∞–µ–º—ã–π –æ—Ç–≤–µ—Ç': test.get('expected_answer', '')[:30] + '...' if len(test.get('expected_answer', '')) > 30 else test.get('expected_answer', ''),
                                        '–ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å': "‚úÖ" if test.get('score', 0) == 1 else "‚ùå",
                                        '–í—Ä–µ–º—è (—Å–µ–∫)': f"{test.get('time_taken', 0):.2f}"
                                    })
                                
                                results_df = pd.DataFrame(results_data)
                                st.dataframe(results_df, use_container_width=True)
                                
                                # –í—ã–±–æ—Ä —Ç–µ—Å—Ç–∞ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞
                                test_options = [f"–¢–µ—Å—Ç {test['test_id']}: {test['question'][:50]}..." 
                                              for test in test_results]
                                
                                selected_test_idx = st.selectbox(
                                    "–í—ã–±–µ—Ä–∏—Ç–µ —Ç–µ—Å—Ç –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞:",
                                    range(len(test_options)),
                                    format_func=lambda x: test_options[x]
                                )
                                
                                if selected_test_idx is not None:
                                    selected_test = test_results[selected_test_idx]
                                    
                                    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–µ—Ç–∞–ª–µ–π —Ç–µ—Å—Ç–∞
                                    col1, col2 = st.columns([1, 1])
                                    
                                    with col1:
                                        st.write("**–í–æ–ø—Ä–æ—Å:**")
                                        st.write(selected_test.get('question', ''))
                                        
                                        st.write("**–û–∂–∏–¥–∞–µ–º—ã–π –æ—Ç–≤–µ—Ç:**")
                                        st.write(selected_test.get('expected_answer', ''))
                                    
                                    with col2:
                                        st.write("**–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç–≤–µ—Ç:**")
                                        st.write(selected_test.get('actual_answer', ''))
                                        
                                        # –°—Ç–∞—Ç—É—Å —Å —Ü–≤–µ—Ç–æ–≤–æ–π –∏–Ω–¥–∏–∫–∞—Ü–∏–µ–π
                                        is_correct = selected_test.get('score', 0) == 1
                                        if is_correct:
                                            st.success("**–û—Ü–µ–Ω–∫–∞:** –ü–†–ê–í–ò–õ–¨–ù–û")
                                        else:
                                            st.error("**–û—Ü–µ–Ω–∫–∞:** –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û")
                                    
                                    # –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏
                                    explanation = selected_test.get('explanation', '')
                                    if explanation:
                                        st.write("**–û–±—ä—è—Å–Ω–µ–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏:**")
                                        st.info(explanation)
                
                except UnicodeDecodeError:
                    st.error("–û—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ —Ñ–∞–π–ª–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∞–π–ª –≤ UTF-8.")
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
    
    elif mode == "–†–∞–∑–º–µ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–æ–≤":
        st.header("–†—É—á–Ω–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–æ–≤")
        
        st.markdown("""
        **–†—É—á–Ω–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è**
        
        –ó–¥–µ—Å—å –≤—ã –º–æ–∂–µ—Ç–µ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∏ –æ—Ü–µ–Ω–∏—Ç—å –æ—Ç–≤–µ—Ç—ã, —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–∏—Å—Ç–µ–º–æ–π RAG.
        –í–∞—à–∏ –æ—Ü–µ–Ω–∫–∏ –ø–æ–º–æ–≥—É—Ç —É–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ —Å–∏—Å—Ç–µ–º—ã.
        """)
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤
        try:
            unrated_tests = postgres_storage.get_unrated_tests(limit=50)
            
            if not unrated_tests:
                st.info("–í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–µ—Å—Ç—ã —É–∂–µ —Ä–∞–∑–º–µ—á–µ–Ω—ã! üéâ")
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞–∑–º–µ—Ç–∫–∏
                rating_stats = postgres_storage.get_rating_statistics()
                if rating_stats:
                    st.subheader("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞–∑–º–µ—Ç–∫–∏")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("–í—Å–µ–≥–æ —Ä–∞–∑–º–µ—á–µ–Ω–æ", rating_stats.get('total_rated', 0))
                    with col2:
                        st.metric("–ü—Ä–∞–≤–∏–ª—å–Ω—ã—Ö", rating_stats.get('correct_count', 0))
                    with col3:
                        accuracy = 0
                        if rating_stats.get('total_rated', 0) > 0:
                            accuracy = (rating_stats.get('correct_count', 0) / rating_stats.get('total_rated', 1)) * 100
                        st.metric("–¢–æ—á–Ω–æ—Å—Ç—å", f"{accuracy:.1f}%")
            else:
                st.success(f"–ù–∞–π–¥–µ–Ω–æ {len(unrated_tests)} –Ω–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤")
                
                # –í—ã–±–æ—Ä —Ç–µ—Å—Ç–∞ –¥–ª—è —Ä–∞–∑–º–µ—Ç–∫–∏
                test_options = [
                    f"–¢–µ—Å—Ç #{test['id']}: {test['question'][:80]}..." 
                    if len(test['question']) > 80 
                    else f"–¢–µ—Å—Ç #{test['id']}: {test['question']}"
                    for test in unrated_tests
                ]
                
                selected_test_idx = st.selectbox(
                    "–í—ã–±–µ—Ä–∏—Ç–µ —Ç–µ—Å—Ç –¥–ª—è —Ä–∞–∑–º–µ—Ç–∫–∏:",
                    range(len(test_options)),
                    format_func=lambda x: test_options[x]
                )
                
                if selected_test_idx is not None:
                    selected_test = unrated_tests[selected_test_idx]
                    
                    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–µ—Å—Ç–µ
                    st.subheader(f"–¢–µ—Å—Ç #{selected_test['id']}")
                    
                    col1, col2 = st.columns([1, 1])
                    
                    with col1:
                        st.write("**–í–æ–ø—Ä–æ—Å:**")
                        st.info(selected_test['question'])
                        
                        st.write("**–û–∂–∏–¥–∞–µ–º—ã–π –æ—Ç–≤–µ—Ç:**")
                        st.success(selected_test['expected_answer'])
                        
                        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                        st.write("**–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:**")
                        st.write(f"- **–ò–Ω–¥–µ–∫—Å:** {selected_test['index_name']}")
                        st.write(f"- **–í—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:** {selected_test['test_timestamp']}")
                        st.write(f"- **ID —Å–µ—Å—Å–∏–∏:** {selected_test['test_session_id']}")
                        
                        # –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                        if selected_test.get('search_time_ms'):
                            st.write(f"- **–í—Ä–µ–º—è –ø–æ–∏—Å–∫–∞:** {selected_test['search_time_ms']} –º—Å")
                        if selected_test.get('generation_time_ms'):
                            st.write(f"- **–í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:** {selected_test['generation_time_ms']} –º—Å")
                        if selected_test.get('total_time_ms'):
                            st.write(f"- **–û–±—â–µ–µ –≤—Ä–µ–º—è:** {selected_test['total_time_ms']} –º—Å")
                    
                    with col2:
                        st.write("**–û—Ç–≤–µ—Ç —Å–∏—Å—Ç–µ–º—ã RAG:**")
                        st.warning(selected_test['actual_answer'])
                        
                        # –§–æ—Ä–º–∞ –¥–ª—è —Ä–∞–∑–º–µ—Ç–∫–∏
                        st.write("**–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–∞:**")
                        
                        is_correct = st.radio(
                            "–Ø–≤–ª—è–µ—Ç—Å—è –ª–∏ –æ—Ç–≤–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º?",
                            options=[True, False],
                            format_func=lambda x: "‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ" if x else "‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ",
                            key=f"rating_{selected_test['id']}"
                        )
                        
                        comment = st.text_area(
                            "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):",
                            placeholder="–û–±—ä—è—Å–Ω–∏—Ç–µ –ø–æ—á–µ–º—É –æ—Ç–≤–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∏–ª–∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π...",
                            key=f"comment_{selected_test['id']}"
                        )
                        
                        # –ö–Ω–æ–ø–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ç–∫–∏
                        if st.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ü–µ–Ω–∫—É", type="primary", key=f"save_{selected_test['id']}"):
                            try:
                                postgres_storage.save_user_rating(
                                    test_id=selected_test['id'],
                                    is_correct=is_correct,
                                    comment=comment,
                                    rated_by="streamlit_user"
                                )
                                st.success("–û—Ü–µ–Ω–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞! ‚úÖ")
                                st.experimental_rerun()
                            except Exception as e:
                                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –æ—Ü–µ–Ω–∫–∏: {e}")
        
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
    
    elif mode == "–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π":
        st.header("–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤")
        
        st.markdown("""
        **–ê–Ω–∞–ª–∏–∑ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π**
        
        –ó–¥–µ—Å—å –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∑–∞–ø—Ä–æ—Å–∞–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –≤–∫–ª—é—á–∞—è –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã,
        –≤—Ä–µ–º—è –æ—Ç–∫–ª–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã –∏ –æ–±—â—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å.
        """)
        
        try:
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—â–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            stats = postgres_storage.get_user_queries_statistics()
            
            if stats.get('total_queries', 0) == 0:
                st.info("–ü–æ–∫–∞ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–∞—Ö. –í—ã–ø–æ–ª–Ω–∏—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏.")
            else:
                # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤", stats.get('total_queries', 0))
                with col2:
                    st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π", stats.get('unique_users', 0))
                with col3:
                    success_rate = 0
                    if stats.get('total_queries', 0) > 0:
                        success_rate = (stats.get('successful_queries', 0) / stats.get('total_queries', 1)) * 100
                    st.metric("–£—Å–ø–µ—à–Ω–æ—Å—Ç—å", f"{success_rate:.1f}%")
                with col4:
                    avg_time = stats.get('avg_total_time_ms', 0) or 0
                    st.metric("–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è", f"{avg_time:.0f} –º—Å")
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–µ—Å—Å–∏–π", stats.get('unique_sessions', 0))
                with col2:
                    st.metric("–ò–Ω–¥–µ–∫—Å–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è", stats.get('indices_used', 0))
                with col3:
                    st.metric("–ù–µ—É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤", stats.get('failed_queries', 0))
                
                # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                st.subheader("–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å")
                col1, col2, col3 = st.columns(3)
                with col1:
                    avg_search = stats.get('avg_search_time_ms', 0) or 0
                    st.metric("–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞", f"{avg_search:.0f} –º—Å")
                with col2:
                    avg_generation = stats.get('avg_generation_time_ms', 0) or 0
                    st.metric("–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏", f"{avg_generation:.0f} –º—Å")
                with col3:
                    max_time = stats.get('max_total_time_ms', 0) or 0
                    st.metric("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è", f"{max_time:.0f} –º—Å")
                
                # –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
                st.subheader("–ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã")
                
                popular_queries = postgres_storage.get_popular_queries(limit=10)
                
                if popular_queries:
                    popular_data = []
                    for query in popular_queries:
                        popular_data.append({
                            '–ó–∞–ø—Ä–æ—Å': query['query_text'][:80] + '...' if len(query['query_text']) > 80 else query['query_text'],
                            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤': query['query_count'],
                            '–ü–æ—Å–ª–µ–¥–Ω–∏–π —Ä–∞–∑': query['last_used'].strftime('%Y-%m-%d %H:%M:%S'),
                            '–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è (–º—Å)': f"{query.get('avg_time_ms', 0):.0f}"
                        })
                    
                    popular_df = pd.DataFrame(popular_data)
                    st.dataframe(popular_df, use_container_width=True)
                else:
                    st.info("–ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –ø–æ–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç.")
                
                # –ü–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø—Ä–æ—Å—ã
                st.subheader("–ü–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø—Ä–æ—Å—ã")
                
                recent_queries = postgres_storage.get_recent_queries(limit=20)
                
                if recent_queries:
                    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
                    recent_data = []
                    for query in recent_queries:
                        status = "–£—Å–ø–µ—à–Ω–æ" if query['success'] else "–û—à–∏–±–∫–∞"
                        
                        recent_data.append({
                            '–í—Ä–µ–º—è': query['timestamp'].strftime('%Y-%m-%d %H:%M:%S'),
                            '–ó–∞–ø—Ä–æ—Å': query['query_text'][:80] + '...' if len(query['query_text']) > 80 else query['query_text'],
                            '–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å': query['user_id'],
                            '–ò–Ω–¥–µ–∫—Å': query['index_name'] or '–ù/–î',
                            '–°—Ç–∞—Ç—É—Å': status,
                            '–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (–º—Å)': query.get('total_time_ms', 0) or 0
                        })
                    
                    recent_df = pd.DataFrame(recent_data)
                    st.dataframe(recent_df, use_container_width=True)
                    
                    # –î–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –∑–∞–ø—Ä–æ—Å–∞
                    st.subheader("–î–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä")
                    
                    query_options = [
                        f"{q['timestamp'].strftime('%H:%M:%S')} - {q['query_text'][:50]}..." 
                        if len(q['query_text']) > 50 
                        else f"{q['timestamp'].strftime('%H:%M:%S')} - {q['query_text']}"
                        for q in recent_queries
                    ]
                    
                    selected_query_idx = st.selectbox(
                        "–í—ã–±–µ—Ä–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞:",
                        range(len(query_options)),
                        format_func=lambda x: query_options[x],
                        key="analytics_query_selector"
                    )
                    
                    if selected_query_idx is not None:
                        selected_query = recent_queries[selected_query_idx]
                        
                        col1, col2 = st.columns([1, 1])
                        
                        with col1:
                            st.write("**–î–µ—Ç–∞–ª–∏ –∑–∞–ø—Ä–æ—Å–∞:**")
                            st.write(f"**–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å:** {selected_query['user_id']}")
                            st.write(f"**–í—Ä–µ–º—è:** {selected_query['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}")
                            st.write(f"**–ò–Ω–¥–µ–∫—Å:** {selected_query['index_name'] or '–ù–µ —É–∫–∞–∑–∞–Ω'}")
                            st.write(f"**–°—Ç–∞—Ç—É—Å:** {'–£—Å–ø–µ—à–Ω–æ' if selected_query['success'] else '–û—à–∏–±–∫–∞'}")
                            
                            if selected_query.get('error_message'):
                                st.error(f"**–û—à–∏–±–∫–∞:** {selected_query['error_message']}")
                        
                        with col2:
                            st.write("**–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:**")
                            if selected_query.get('search_time_ms'):
                                st.write(f"**–í—Ä–µ–º—è –ø–æ–∏—Å–∫–∞:** {selected_query['search_time_ms']} –º—Å")
                            if selected_query.get('generation_time_ms'):
                                st.write(f"**–í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:** {selected_query['generation_time_ms']} –º—Å")
                            if selected_query.get('total_time_ms'):
                                st.write(f"**–û–±—â–µ–µ –≤—Ä–µ–º—è:** {selected_query['total_time_ms']} –º—Å")
                        
                        st.write("**–ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞:**")
                        st.info(selected_query['query_text'])
                        
                        if selected_query.get('response_text'):
                            st.write("**–û—Ç–≤–µ—Ç —Å–∏—Å—Ç–µ–º—ã:**")
                            st.success(selected_query['response_text'][:500] + '...' if len(selected_query['response_text']) > 500 else selected_query['response_text'])
                else:
                    st.info("–ü–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø—Ä–æ—Å—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç.")
        
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏: {e}")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è."""
    create_streamlit_interface()


if __name__ == "__main__":
    main() 